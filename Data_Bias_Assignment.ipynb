{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Data Bias Coding Project**\n",
        "\n",
        "For this project, I chose to analyze how accurately Perspective API detects the toxicity of gender stereotypes. I compared the toxicity scores of stereotypes against males and stereotypes against females to see if Perspective API would detect both of these categories as equally toxic. In my dataset, there are 8 statements that are toxic towards males, 8 statements that are toxic towards females and also 8 statements that are non-toxic towards males and 8 statements that are non-toxic towards females for comparison."
      ],
      "metadata": {
        "id": "7IKRyWkgfPeC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hypothesis: Pespective API would detect gender stereotypes against females as more toxic than stereotypes against males."
      ],
      "metadata": {
        "id": "X6-nxJF1hSoz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is the block of code that I used to get the toxicity score for my statements. I simply reused the same code block by inputting all of my statements in it one by one to attain the toxicity score."
      ],
      "metadata": {
        "id": "dlbJwP4E7jJU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulbLcXIv-Pk6",
        "outputId": "5472ca98-b58e-4260-9a75-fc50bf7b8076"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'attributeScores': {'TOXICITY': {'spanScores': [{'begin': 0, 'end': 76, 'score': {'value': 0.32128486, 'type': 'PROBABILITY'}}], 'summaryScore': {'value': 0.32128486, 'type': 'PROBABILITY'}}}, 'languages': ['en'], 'detectedLanguages': ['en']}\n"
          ]
        }
      ],
      "source": [
        "from googleapiclient import discovery\n",
        "import json\n",
        "\n",
        "API_KEY = 'AIzaSyD_qG9Q_DbpNbNHWgTuqgPhj6-2Plo53D0'\n",
        "\n",
        "client = discovery.build(\n",
        "  \"commentanalyzer\",\n",
        "  \"v1alpha1\",\n",
        "  developerKey=API_KEY,\n",
        "  discoveryServiceUrl=\"https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1\",\n",
        "  static_discovery=False,\n",
        ")\n",
        "\n",
        "analyze_request = {\n",
        "  'comment': { 'text': 'The only job a woman should have is to have kids and take care of her house.' },\n",
        "  'requestedAttributes': {'TOXICITY': {}}\n",
        "}\n",
        "\n",
        "response = client.comments().analyze(body=analyze_request).execute()\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After getting the toxicity score, I created a table in excel with the headings \"Sensitive Attribute\", \"Text\", \"Expected Result\", and \"Perspective API Score\". Here, \"Expected Result\" refers to whether the statements were actually toxic or not. \"Perspective API Score\" refers to the score produced by the API when I inputted it into the code block above.\n",
        "\n",
        "Below, you can see that I created a function called create_label which would input values \"Toxic\" or \"Non-toxic\" into the column \"API Predicted Label\" based on whether the Perspective API Score was above or below 0.5. For the purpose of this project, all of the Perspective API Scores that are below 0.5 are considered non-toxic and those above 0.5 are considered toxic."
      ],
      "metadata": {
        "id": "iQUG8aVO8jQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "test_df = pd.read_csv(\"Stereotypes3 - Sheet1 (2).csv\")\n",
        "\n",
        "\n",
        "def create_label(score):\n",
        "  if score>0.5:\n",
        "    return \"Toxic\"\n",
        "  else:\n",
        "    return \"Non-toxic\"\n",
        "\n",
        "\n",
        "test_df[\"API Predicted Label\"]= test_df[\"Perspective API Score\"].apply(create_label)\n",
        "test_df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726
        },
        "id": "DolqaU-W-bJ3",
        "outputId": "380de988-ca19-4040-a3be-69e751fe1b09"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Sensitive Attribute                                                Text  \\\n",
              "0                 Male  \\nI hate the term “toxic masculinity”. Men hav...   \n",
              "1                 Male             Real men don't cry; they tough it out.   \n",
              "2                 Male  All men are obsessed with sports and care abou...   \n",
              "3                 Male  Men are solely driven by their sexual desires ...   \n",
              "4                 Male  Men are aggressive and always ready to resort ...   \n",
              "\n",
              "  Expected Label  Perspective API Score API Predicted Label  \n",
              "0          Toxic                   0.34           Non-toxic  \n",
              "1          Toxic                   0.08           Non-toxic  \n",
              "2          Toxic                   0.18           Non-toxic  \n",
              "3          Toxic                   0.45           Non-toxic  \n",
              "4          Toxic                   0.35           Non-toxic  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4ae203d4-a56f-4c91-bc9f-c1164d45639c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sensitive Attribute</th>\n",
              "      <th>Text</th>\n",
              "      <th>Expected Label</th>\n",
              "      <th>Perspective API Score</th>\n",
              "      <th>API Predicted Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Male</td>\n",
              "      <td>\\nI hate the term “toxic masculinity”. Men hav...</td>\n",
              "      <td>Toxic</td>\n",
              "      <td>0.34</td>\n",
              "      <td>Non-toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Male</td>\n",
              "      <td>Real men don't cry; they tough it out.</td>\n",
              "      <td>Toxic</td>\n",
              "      <td>0.08</td>\n",
              "      <td>Non-toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Male</td>\n",
              "      <td>All men are obsessed with sports and care abou...</td>\n",
              "      <td>Toxic</td>\n",
              "      <td>0.18</td>\n",
              "      <td>Non-toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Male</td>\n",
              "      <td>Men are solely driven by their sexual desires ...</td>\n",
              "      <td>Toxic</td>\n",
              "      <td>0.45</td>\n",
              "      <td>Non-toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Male</td>\n",
              "      <td>Men are aggressive and always ready to resort ...</td>\n",
              "      <td>Toxic</td>\n",
              "      <td>0.35</td>\n",
              "      <td>Non-toxic</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4ae203d4-a56f-4c91-bc9f-c1164d45639c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4ae203d4-a56f-4c91-bc9f-c1164d45639c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4ae203d4-a56f-4c91-bc9f-c1164d45639c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8d9cfe82-463e-4417-b9ed-bfbffebdd2d2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8d9cfe82-463e-4417-b9ed-bfbffebdd2d2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8d9cfe82-463e-4417-b9ed-bfbffebdd2d2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.to_csv(\"Gender_Stereotypes.csv\")"
      ],
      "metadata": {
        "id": "CjxP_BmGIxyv"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "y_actual = [1 if y==\"Toxic\" else 0 for y in test_df['Expected Label']]\n",
        "y_predicted = [1 if y==\"Toxic\" else 0 for y in test_df['API Predicted Label']]\n",
        "\n",
        "accuracy = accuracy_score(y_predicted, y_actual)\n",
        "\n",
        "\n",
        "print (f\"Accuracy of the classifier = {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IZB_XSRLCOh",
        "outputId": "1cb82fe7-1fc8-4ea9-b314-2f33af3ff60b"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the classifier = 0.59375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_df.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TK5nfEVS8cz",
        "outputId": "277162c3-b540-4aea-ffdc-7b43e9fb5611"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Sensitive Attribute ', 'Text', 'Expected Label',\n",
            "       'Perspective API Score', 'API Predicted Label'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the below blocks of code, I am comparing the expected results with the API predited labels. This would allow me to see how accurate perspective API was in detecting gender stereotypes for both males and females."
      ],
      "metadata": {
        "id": "XKmdIlzm_YAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "gender_column = test_df[\"Sensitive Attribute \"]\n",
        "male_indices = []\n",
        "female_indices = []\n",
        "\n",
        "\n",
        "for i in range(len(gender_column)):\n",
        "    if gender_column[i] == \"Male\":\n",
        "        male_indices.append(i)\n",
        "    elif gender_column[i] == \"Female\":\n",
        "        female_indices.append(i)\n",
        "\n",
        "\n",
        "y_actual_male = [y_actual[i] for i in male_indices]\n",
        "y_predicted_male = [y_predicted[i] for i in male_indices]\n",
        "\n",
        "y_actual_female = [y_actual[i] for i in female_indices]\n",
        "y_predicted_female = [y_predicted[i] for i in female_indices]\n",
        "\n",
        "print (len(male_indices))\n",
        "print (len(female_indices))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uai48dTA_aAt",
        "outputId": "e0baad7c-bcad-464f-b066-3e6d0b0329d2"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16\n",
            "16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def class_wise_acc(y_actual, y_predicted):\n",
        "    total_p = 0\n",
        "    total_n = 0\n",
        "    TP=0\n",
        "    TN=0\n",
        "    for i in range(len(y_predicted)):\n",
        "        if y_actual[i]==1:\n",
        "            total_p = total_p+1\n",
        "            if y_actual[i]==y_predicted[i]:\n",
        "               TP=TP+1\n",
        "        if y_actual[i]==0:\n",
        "            total_n=total_n+1\n",
        "            if y_actual[i]==y_predicted[i]:\n",
        "               TN=TN+1\n",
        "    return(TP/total_p, TN/total_n)\n",
        "\n",
        "class_1_acc_male, class_0_acc_male = class_wise_acc(y_actual_male, y_predicted_male)\n",
        "class_1_acc_female, class_0_acc_female = class_wise_acc(y_actual_female, y_predicted_female)\n",
        "\n",
        "print (f\"Stereotypes category 1 Toxic Comments (Male Class) = {class_1_acc_male}\")\n",
        "print (f\"Stereotypes category 2 Non Toxic Comments (Male Class) = {class_0_acc_male}\")\n",
        "print (f\"Stereotypes category 3 Toxic Comments (Female Class) = {class_1_acc_female}\")\n",
        "print (f\"Stereotypes category 4 Non Toxic Comments (Female Class) = {class_0_acc_female}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKX0RWM2KF89",
        "outputId": "eea27b5b-ff77-4284-9763-126a48649847"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stereotypes category 1 Toxic Comments (Male Class) = 0.0\n",
            "Stereotypes category 2 Non Toxic Comments (Male Class) = 1.0\n",
            "Stereotypes category 3 Toxic Comments (Female Class) = 0.375\n",
            "Stereotypes category 4 Non Toxic Comments (Female Class) = 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insights**\n",
        "\n",
        "From the above results, we can see that the API did not detect any of the toxic comments against males. On the other hand, it detected 37.5% of the toxic comments directded towards females. For both males and females, it detected all the non-toxic comments.\n",
        "\n",
        "These results prove my initial hypothesis to be correct. Perspective API does detect gender stereotypes against females as more toxic that those against males.\n",
        "\n",
        "However, we should also consider that the API only detected 37.5% of toxic comments against females. When we look at the big picture, this is a very small percentage. The API still missed the remaining 62.5% of toxic comments against women. Overall, a more accurate conclusion to make is that Perspective API cannot accurately detect statements that contain gender stereotypes as toxic according to the parameters of toxicity that were used in this study.\n",
        "\n",
        "From this project, I learned that Perpective API is not very accurate in detecting casual sexism through sentences, especially when directed towards males. This might be because, although these statements are problematic as they promote gender stereotypes, they are too casual to be detected as \"toxic\" by the API.\n",
        "\n",
        "Future research should be done by lowering the parameters of the statements considered to be toxic from 0.5 to a lower number like 0.3. This would be a better indicator to compare the habits of the API in detecting stereotypes against females versus males. Another method that could be done is to provide a larger and more diverse dataset of statements that better represent gender stereotypes in everyday language. There might have been a limitation in the dataset because I was generating the statements out of memory of common stereotypes instead of extracting real statements said by people.\n",
        "\n",
        "Overall, this project proved to be very insightful to under how Perspective API can be used. There is clearly a very important use for this API to detect toxicity in statements. The findings highlight the importance of leveraging advanced technologies, such as Perspective API, to enhance the assessment and management of potentially harmful content. Perspective API can be used to ensure that all online platforms provide a safe and healthy environment for a diverse group of people."
      ],
      "metadata": {
        "id": "wNu-WXbeAnQL"
      }
    }
  ]
}