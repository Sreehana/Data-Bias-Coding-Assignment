Introduction: For this project, I chose to analyze how accurately Perspective API detects the toxicity of gender stereotypes. I compared the toxicity scores of stereotypes against males and stereotypes against females to see if Perspective API would detect both of these categories as equally toxic. In my dataset, there are 8 statements that are toxic towards males, 8 statements that are toxic towards females and also 8 statements that are non-toxic towards males and 8 statements that are non-toxic towards females for comparison. 

Hypothesis: Pespective API would detect gender stereotypes against females as more toxic than stereotypes against males. 

Insights, Conclusions and Limitations
Results: From the above results, we can see that the API did not detect any of the toxic comments against males. On the other hand, it detected 37.5% of the toxic comments directded towards females. For both males and females, it detected all the non-toxic comments.

Conclusions: These results prove my initial hypothesis to be correct. Perspective API does detect gender stereotypes against females as more toxic that those against males. However, we should also consider that the API only detected 37.5% of toxic comments against females. When we look at the big picture, this is a very small percentage. The API still missed the remaining 62.5% of toxic comments against women. Overall, a more accurate conclusion to make is that Perspective API cannot accurately detect statements that contain gender stereotypes as toxic according to the parameters of toxicity that were used in this study. 

Key takeaway: From this project, I learned that Perpective API is not very accurate in detecting casual sexism through sentences, especially when directed towards males. This might be because, although these statements are problematic as they promote gender stereotypes, they are too casual to be detected as "toxic" by the API. 

Scope for further research and limitations: Future research should be done by lowering the parameters of the statements considered to be toxic from 0.5 to a lower number like 0.3. This would be a better indicator to compare the habits of the API in detecting stereotypes against females versus males. Another method that could be done is to provide a larger and more diverse dataset of statements that better represent gender stereotypes in everyday language. There might have been a limitation in the dataset because I was generating the statements out of memory of common stereotypes instead of extracting real statements said by people. 

Final thoughts: Overall, this project proved to be very insightful to under how Perspective API can be used. There is clearly a very important use for this API to detect toxicity in statements. The findings highlight the importance of leveraging advanced technologies, such as Perspective API, to enhance the assessment and management of potentially harmful content. Perspective API can be used to ensure that all online platforms provide a safe and healthy environment for a diverse group of people.
